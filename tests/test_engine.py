"""Tests the basic operations (mix, add, convolve, etc.) for the various engines"""

import itertools
from typing import Iterable

import numpy as np
import numpy.random
import pytest

from wavesim.engine import (
    BlockArray,
    NumpyArray,
    SparseArray,
    scale,
    shape_like,
    ax_,
    mix,
    multiply,
    copy,
    add,
    subtract,
    lerp,
    Array,
    new_like,
    empty_like,
    zeros_like,
    convolve,
    deconvolve,
    clone,
    ConstantArray,
    matmul,
    CupyArray,
)
from . import all_close


def vector_generator(
    *,
    backend,
    for_output=False,
    shape: tuple[int, ...] = (3, 4, 5),
) -> tuple[Array, ...]:
    """Helper function to generate different types vectors for testing the basic operations.

    Returns:
        A tuple of Arrays.
    """

    data = np.random.normal(scale=np.sqrt(0.5), size=shape) + 1.0j * np.random.normal(scale=np.sqrt(0.5), size=shape)
    data.setflags(write=False)
    data = data.astype(np.complex64)
    a1 = backend(data, copy=True)
    boundaries = ((2,), (1, 3), (2,)) + ((),) * (data.ndim - 2)
    a2 = BlockArray(backend(data, copy=True), boundaries=boundaries[: data.ndim])
    # a3 = partition(engine(data), (3, 1, 3, 2, 1, 2, 1, 2)[: len(shape)])  # different partitioning

    if for_output:  # don't return the sparse array since it cannot be used for output operations
        return a1, a2  # , a3

    s1 = SparseArray.point(value=1.0, at=(0,) * len(shape), shape=shape)
    c1 = ConstantArray(2.0, shape=shape)
    return a1, a2, s1, c1


def unpack(input: Iterable[Array]):
    """Takes a tuple of Array objects, and returns the corresponding data and Array objects interleaved."""
    return sum([(x.gather().copy(), x) for x in input], ())


def ids(input):
    """Helper function to assign labels to the test cases generated by 'vectors'"""

    def _ids(x):
        if isinstance(x, Array):
            id = x.__class__.__name__
            if x is input[-1]:
                id += "_out"
            return id
        return str(x)

    try:
        return ", ".join(_ids(x) for x in input if isinstance(x, Array))
    except TypeError:
        return str(input)


def vectors(input_count: int, **kwargs):
    """Constructs a sequence of any number of input vectors and one output (out) vectors from different engines

    The sequence contains all combinations of NumpyArray, BlockArray (2 different splittings), and SparseArray for the input vectors.
    The output vector is either a new NumpyArray or a BlockArray, or one of the inputs, to test in-place operations

    Returns: a tuple or Arrays of the vectors, with the output array at the end.
    """
    # first generate the input vectors
    for backend in [NumpyArray, CupyArray]:
        inputs = tuple(vector_generator(backend=backend, **kwargs) for _ in range(input_count))
        outputs = vector_generator(for_output=True, backend=backend, **kwargs)

        # create all combinations of input/output vectors
        for combination in itertools.product(*inputs, outputs):
            yield combination

            # also test in-place operations, using one of the inputs as an output
            # this requires cloning the input data to avoid it being overwritten
            for i, array in enumerate(combination[:-1]):
                if array.is_full:
                    array_clone = clone(array)
                    in_place_combination = list(combination)
                    in_place_combination[i] = array_clone
                    in_place_combination[-1] = array_clone
                    yield tuple(in_place_combination)


@pytest.mark.parametrize("output", list(vectors(0)), ids=ids)
def test_clone(output):
    x, ax = unpack(output)
    assert all_close(x, ax)
    cax = clone(ax)
    # modify cax
    copy(-1.0, out=cax)
    assert not all_close(x, cax, plot=False)
    assert all_close(x, ax)


@pytest.mark.parametrize("output", list(vectors(0)), ids=ids)
@pytest.mark.parametrize("case", ("same_type", "NumpyArray", "scalar", "different_dtype"))
def test_set_with_array(output, case):
    original = output[0]
    original_dtype = original.dtype
    original_shape = original.shape
    y = np.random.uniform(size=original_shape)

    if case == "same_type":
        y = y.astype(original_dtype)
        new_data = new_like(original, y)
    elif case == "NumpyArray":
        new_data = NumpyArray(y)
    elif case == "scalar":
        new_data = 5.0
    else:  # case == "different_dtype":
        # in this case, the copy should convert from float32 to complex64
        new_data = new_like(original, y)

    copy(new_data, out=original)
    odata = original.gather()
    assert all_close(odata, new_data)
    assert original.dtype == original_dtype == odata.dtype
    assert original.shape == original_shape == odata.shape


def block_engine(data, shape: shape_like = None, **kwargs):
    shape = data.shape if shape is None else shape
    return BlockArray(
        data, boundaries=[(s // 2,) for s in shape], copy=True, shape=shape, factories=NumpyArray, **kwargs
    )


def numpy_engine(data, **kwargs):
    return NumpyArray(data, copy=True, **kwargs)


@pytest.mark.parametrize("engine", [numpy_engine, block_engine])
def test_allocate(engine):
    """Tests allocating new arrays and gathering back the data"""

    # assign with array value
    x = numpy.random.uniform(size=(2, 3, 4))
    ax = engine(x)
    assert ax.shape == x.shape
    assert all_close(x, ax)

    # assign with constant value
    ax = engine(1.0, shape=x.shape)

    assert ax.shape == x.shape
    assert all_close(1.0, ax)

    with pytest.raises((ValueError, AttributeError)):
        engine(1.0)  # missing shape

    # allocate non-initialized
    ax = engine(None, shape=x.shape, dtype=np.float32)
    assert ax.shape == x.shape


@pytest.mark.parametrize("engine", [NumpyArray, block_engine])
def test_like(engine):
    """Tests new_like, empty_like zeros_like"""

    # assign with array value
    x = numpy.random.uniform(size=(2, 3, 4)).astype(np.float32)
    ax = engine(x)
    assert ax.shape == x.shape
    assert ax.dtype == np.float32
    assert all_close(ax, x)

    ax2 = new_like(ax, (x + 1).astype(np.complex128))
    assert ax2.shape == x.shape
    assert ax2.dtype == np.float32
    assert all_close(ax2, x + 1)

    ax3 = empty_like(ax)
    assert ax3.shape == ax.shape
    assert ax3.dtype == np.float32

    ax4 = empty_like(ax, dtype=np.complex128)
    assert ax4.shape == ax.shape
    assert ax4.dtype == np.complex128

    ax0 = zeros_like(ax)
    assert ax0.shape == ax.shape
    assert ax0.dtype == np.float32
    assert all_close(ax0, 0)

    # change shape.
    if isinstance(ax, NumpyArray):
        ax5 = new_like(ax, x.flatten())
        assert ax5.shape == x.flatten().shape
        assert ax5.dtype == np.float32
        assert all_close(ax5, x.flatten())

        ax6 = zeros_like(ax, shape=(1, 2))
        assert ax6.shape == (1, 2)
        assert ax6.dtype == np.float32
        assert all_close(ax6, 0)
    else:
        # with a block array, you cannot change the dimensionality without specifying a new set of boundaries
        with pytest.raises(ValueError):
            new_like(ax, x.flatten())
        # with a block array, you can change the shape, but the boundaries are not updated
        # if the shape is larger, this is fine. If it is smaller than the internal boundaries, it will raise an error
        ax6 = new_like(ax, 3.0, shape=(5, 6, 7))  # this is fine. The boundaries are compatible with the new shape
        assert ax6.shape == (5, 6, 7)
        with pytest.raises(ValueError):
            # this is not fine. The boundaries are not compatible with the new shape (too small)
            ax7 = new_like(ax, 3.0, shape=(1, 1, 1))
        with pytest.raises(ValueError):
            # this is not fine. The boundaries are not compatible with the new shape
            ax8 = new_like(ax, 3.0, shape=(5, 6))
        ax9 = new_like(ax, 3.0, shape=(5, 6), boundaries=((2,), (2, 4)))


@pytest.mark.parametrize("output", list(vectors(0)))
def test_mutable(output):
    """Tests if the array is mutable"""
    ax = output[0]
    copy(-1.0, out=ax[0, 0, 0])
    assert all_close(ax.gather()[0, 0, 0], -1)


@pytest.mark.parametrize("input", vectors(2), ids=ids)
def test_add(input):
    """Tests adding two arrays"""
    x, ax, y, ay, _, az = unpack(input)
    assert all_close(ax, x)
    add(ax, ay, out=az)
    assert all_close(x + y, az)


@pytest.mark.parametrize("input", vectors(2), ids=ids)
def test_subtract(input):
    """Tests subtracting two arrays"""
    x, ax, y, ay, _, az = unpack(input)
    subtract(ax, ay, out=az)
    assert all_close(x - y, az)


@pytest.mark.parametrize("input", vectors(2), ids=ids)
def test_multiply(input):
    """Tests pointwise multiplication of two arrays"""
    x, ax, y, ay, _, az = unpack(input)
    try:
        multiply(ax, ay, out=az)
        assert all_close(x * y, az)
    except NotImplementedError:
        pytest.skip(f"convolve not implemented for data types {type(ax)}, {type(ay)}, {type(az)}.")


@pytest.mark.parametrize("alpha", [1.0, 0.5, 0.0])
@pytest.mark.parametrize("beta", [1.0, 0.2, -1.0, 0.0])
@pytest.mark.parametrize("input", vectors(2), ids=ids)
def test_mix(alpha, beta, input):
    """Tests mixing two arrays"""
    x, ax, y, ay, _, az = unpack(input)
    mix(alpha, ax, beta, ay, out=az)
    assert all_close(alpha * x + beta * y, az)


@pytest.mark.parametrize("input", vectors(3), ids=ids)
def test_lerp(input):
    """Tests linear interpolation between two arrays"""
    x, ax, y, ay, w, aw, _, az = unpack(input)
    try:
        lerp(ax, ay, aw, out=az)
        assert all_close(x + w * (y - x), az)
    except NotImplementedError:
        pytest.skip(f"lerp not implemented for data types {type(ax)}, {type(ay)}, {type(az)}.")


@pytest.mark.parametrize("input", list(vectors(1)), ids=ids)
def test_scale(input):
    """Tests scaling an array"""
    x, ax, _, az = unpack(input)
    scale(2.0, ax, offset=3.0, out=az)
    assert all_close(2.0 * x + 3.0, az)


@pytest.mark.parametrize("input", vectors(2), ids=ids)
def test_convolve(input):
    """Tests convolving and deconvolving two arrays"""
    x, ax, y, ay, _, az = unpack(input)
    if az is ay:
        with pytest.raises((ValueError, NotImplementedError)):
            convolve(ax, ay, out=az)
    else:
        try:
            convolve(ax, ay, out=az)
            if not isinstance(ax, BlockArray) and not isinstance(az, BlockArray):
                correct = np.fft.ifftn(np.fft.fftn(x) * y)
                assert all_close(correct, az)
            deconvolve(az, ay, out=az)
            assert all_close(x, az)
        except NotImplementedError:
            pytest.skip(f"convolve not implemented for data types {type(ax)}, {type(ay)}, {type(az)}.")


@pytest.mark.parametrize("input", vectors(2), ids=ids)
def test_matmul(input):
    """Tests matrix multiplication of two arrays"""
    x, ax, y, ay, _, az_template = unpack(input)
    if isinstance(ax, BlockArray):
        pytest.skip("matmul not implemented for BlockArray in the first input.")
    try:
        for d in range(3):
            o_shape = list(ax.shape)
            o_shape[d] = 7
            az = empty_like(az_template, shape=o_shape)
            m = np.random.uniform(size=(7, x.shape[d]))
            if isinstance(ax, ConstantArray):
                m = 1.0
            matrix = new_like(ax, m)
            matmul(matrix, ax, axis=d, out=az)
            if d == 0:
                correct = np.einsum("ba,acd->bcd", m, x)
            elif d == 1:
                correct = np.einsum("ba,cad->cbd", m, x)
            else:
                correct = np.einsum("ba,cda->cdb", m, x)
            assert all_close(correct, az)
    except NotImplementedError:
        pytest.skip(f"matmul not implemented for data types {type(ax)}, {type(az_template)}.")


@pytest.mark.parametrize("input", list(vectors(2)), ids=ids)
def test_deconvolve(input):
    """Tests convolving two arrays"""
    x, ax, y, ay, _, az = unpack(input)
    if az is ay:
        with pytest.raises((ValueError, NotImplementedError)):
            deconvolve(ax, ay, out=az)
    else:
        try:
            deconvolve(ax, ay, out=az)
            if not isinstance(ax, BlockArray) and not isinstance(az, BlockArray):
                correct = np.fft.ifftn(np.fft.fftn(x) / y)
                assert all_close(correct, az)
            convolve(az, ay, out=az)
            assert all_close(x, az)
        except NotImplementedError:
            pytest.skip(f"deconvolve not implemented for data types {type(ax)}, {type(ay)}, {type(az)}.")


@pytest.mark.parametrize("input", vectors(0), ids=ids)
def test_slicing(input):
    x, ax = unpack(input)
    # zero-size slice
    assert ax[:0, :, :].shape == (0, *ax.shape[1:])

    # zero-size slice of size 1 array
    ax1 = ax[0:1, :, :]
    assert ax1.shape == (1, *ax.shape[1:])
    assert ax1[:0, :, :].shape == (0, *ax.shape[1:])

    # basic slicing
    assert all_close(ax, x)
    assert all_close(ax[1, 2, 1:], x[1, 2, 1:])
    assert all_close(ax[:, 2:, 3:], x[:, 2:, 3:])

    # slicing with negative indices
    assert all_close(ax[-1, -2, -1:], x[-1, -2, -1:])
    assert all_close(ax[:, -2:, -3:], x[:, -2:, -3:])

    # step size not 1
    # assert all_close(x[1:, 2:, ::2], ax[1:, 2:, ::2])
    # assert all_close(x[1:2, 2:3, 3:4:5], ax[1:2, 2:3, 3:4:5])
    # assert all_close(x[1:2:3, 2:3:4, 3:4:5], ax[1:2:3, 2:3:4, 3:4:5])

    # _ax objects
    assert all_close(ax[ax_(1, 2)[1:2, 2:3]], x[:, 1:2, 2:3])

    # test if slices are writable
    ax[0, 1:, 1:2] = -2.0
    assert all_close(ax[0, 1:, 1:2], -2)


@pytest.mark.parametrize("input", vectors(0), ids=ids)
def test_transpose(input):
    x, ax = unpack(input)

    axes = [1, 0, 2]
    ax_t = ax.transpose(axes=axes)
    assert all_close(ax_t, x.transpose(axes))

    # test adding broadcast axes during the transpose
    axes2 = [1, np.newaxis, 0, np.newaxis, 2]
    ax_t2 = ax.transpose(axes=axes2)
    assert all_close(ax_t2.gather(), np.expand_dims(x.transpose(axes), (1, 3)))


@pytest.mark.parametrize("input", vectors(0, shape=(12,)), ids=ids)
def test_transpose_with_to_and_ndim(input):
    # Test transpose with 'to' option
    x, ax = unpack(input)
    ax_t = ax.transpose(axes=0, to=2)
    assert all_close(ax_t, x.reshape((1, 1, -1)))
    ax_t = ax.transpose(axes=0, to=2, ndim=4)
    assert all_close(ax_t, x.reshape((1, 1, -1, 1)))

    # # Test transpose with 'ndim' option only
    # ax_t = ax.transpose(axes=(0, 1, 2), ndim=4)
    # assert all_close(ax_t.gather(), array.reshape((12, 14, 35, 1)))
    #
    # # Test transpose with both 'to' and 'ndim' options
    # ax_t = ax.transpose(axes=(0, 1, 2), to=(0, 3, 2), ndim=4)
    # assert all_close(ax_t.gather(), array.transpose((0, 2, 1)).reshape((12, 1, 35, 14)))
    # ax_t2 = ax.transpose(axes=(0, 1, 2), to=(0, 3, 2))
    # assert all_close(ax_t2.gather(), ax_t.gather())


@pytest.mark.parametrize("input", vectors(0), ids=ids)
def test_broadcast_with_transpose(input):
    x, ax = unpack(input)

    # Broadcast along new axes
    ax_b = ax.transpose(axes=(0, 1, 2), to=(2, 3, 4), ndim=5)
    assert all_close(ax_b.gather(), np.expand_dims(x, (0, 1)))

    # Broadcast along existing and new axes
    ax_b = ax.transpose(axes=(0, 1, np.newaxis, 2), to=(2, 3, 5, 6))
    assert all_close(ax_b.gather(), np.expand_dims(x, (0, 1, 4, 5)))


@pytest.mark.parametrize("input", vectors(1, shape=(30,)), ids=ids)
def test_broadcast(input):
    """
    broadcast x along dim 1, and y along dim 3
    broadcast z along both dims
    then test if these arrays can be added, multiplied, etc.
    """
    x, ax, y, ay = unpack(input)
    assert ax.shape == (30,)
    assert ay.shape == (30,)
    ax_t = ax.transpose(axes=0, to=1, ndim=2)
    ay_t = ay.transpose(axes=0, to=0, ndim=2)
    assert ax_t.shape == (1, 30)
    assert ay_t.shape == (30, 1)
    if isinstance(ax, BlockArray):
        x_boundaries = ax.boundaries[0]
        y_boundaries = ay.boundaries[0] if isinstance(ay, BlockArray) else ()
        az = empty_like(ax, shape=(30, 30), boundaries=(x_boundaries, y_boundaries))
        az2 = empty_like(ax, shape=(30, 30), boundaries=(x_boundaries, y_boundaries))
    elif not ax.is_full:
        return  # empty_like not implemented for SparseArray or ConstArray
    else:
        az = empty_like(ax, shape=(30, 30))
        az2 = empty_like(ax, shape=(30, 30))
    add(ax_t, ay_t, out=az)
    assert all_close(x.reshape(1, -1) + y.reshape(-1, 1), az)

    ax_t2 = ax.transpose(axes=(np.newaxis, 0))
    ay_t2 = ay.transpose(axes=(0, np.newaxis))
    assert ax_t2.shape == (1, 30)
    assert ay_t2.shape == (30, 1)
    add(ax_t2, ay_t2, out=az2)

    assert all_close(ax_t, ax_t2)
    assert all_close(ay_t, ay_t2)
    assert all_close(az, az2)


@pytest.mark.parametrize("engine", [numpy_engine])
def test_sparse(engine):
    # construct a sparse array
    a1 = engine(((1.0, 2.0, 3.0), (4.0, 5.0, 6.0)))
    a2 = engine(((1.0, 2.0),))
    s = SparseArray((a1, a2), at=((0, 5), (3, 5)), shape=(4, 8))
    assert len(s.data) == 2
    sg = s.gather()
    assert sg.shape == (4, 8)
    assert all_close(sg[0:2, 5:8], a1)
    assert all_close(sg[3, 5:7], a2)

    a3 = engine(6.0, shape=(1, 1))
    s3 = SparseArray(a3, at=(0, 0), shape=(4, 8))
    assert len(s3.data) == 1
    print("adding")
    s = s + s3
    assert len(s.data) == 3
    print("gather")
    sg = s.gather()
    assert all_close(sg[0:2, 5:8], a1)
    assert all_close(sg[3, 5:7], a2)
    assert all_close(sg[0, 0], 6)
